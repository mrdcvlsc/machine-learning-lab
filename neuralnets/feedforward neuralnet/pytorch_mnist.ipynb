{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34840302",
   "metadata": {},
   "source": [
    "##### About the code below\n",
    "    this is the overall code of sentdex's 1'st tutorial\n",
    "    from his pytorch series in youtube with some additional code,\n",
    "    his tutorial playlist is in the link below\n",
    "\n",
    "##### Pytorch - Deep learning w/ Python : https://www.youtube.com/playlist?list=PLQVvvaa0QuDdeMyHEYc0gxFpYwHY2Qfdh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81306e7f",
   "metadata": {},
   "source": [
    "## Using pytorch Neural Network module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "318b5940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dbe0ba",
   "metadata": {},
   "source": [
    "##### importing the MNIST digit dataset that we will be using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33f79979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train samples : 60000\n",
      "number of test  samples : 10000\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 784])\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "train = datasets.MNIST(\"\", train=True, download=True, transform = transforms.Compose([transforms.ToTensor()]))\n",
    "test = datasets.MNIST(\"\", train=False, download=True, transform = transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "print('number of train samples :',len(train)) # 60,000\n",
    "print('number of test  samples :',len(test))  # 10,000\n",
    "# the 'train' set inside contains 60,000 2d tensor of images with labels\n",
    "# the 'test'  set inside contains 10,000 2d tensor of images with labels\n",
    "\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# we partioned the train & test sets into batches of 100 into the trainset & testseta.\n",
    "# each iteration of the trainset, and testset when unpacked inside a for loop contains\n",
    "# a tuple or a list with a length size of 2.\n",
    "\n",
    "# let us call each 'iteration' of the trainset as 'data'\n",
    "\n",
    "# the first index of the data == data[0] == a, contains a 100x1x28x28 tensor,\n",
    "# the 100x1 part is a tensor that contains a 28x28 tensor per row\n",
    "# the second index of the data == data[1] == b, constains a 100x tensor array these are the labels\n",
    "# of each 100 samples\n",
    "\n",
    "# when we pass the first index of data == data[0] == a into our network, for each iteration of trainset,\n",
    "# we need to reshape it into a 100x784 tensor where 100 is the batch size,\n",
    "# and 784 is the flatten 28x28 image tensor.\n",
    "# we can do that using the method '.view(-1,28*28)'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997cf7ed",
   "metadata": {},
   "source": [
    "##### importing the neural network module of pytorch and creating our neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d43b33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "nnet = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a0d1bb",
   "metadata": {},
   "source": [
    "##### training our neural network with the MNIST digit dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08df9698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3343, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1276, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0544, grad_fn=<NllLossBackward>)\n",
      "\n",
      "The total training time took 72.91031193733215 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(nnet.parameters(), lr=0.001)\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(3):\n",
    "    for data in trainset:\n",
    "        X, y = data\n",
    "        nnet.zero_grad()\n",
    "        output = nnet(X.view(-1,784))\n",
    "        loss = F.nll_loss(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)\n",
    "    \n",
    "end = time.time()\n",
    "\n",
    "print('\\nThe total training time took',(end-start),'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f890028",
   "metadata": {},
   "source": [
    "##### testing our neural network with MNIST test and training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e419672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset Accuracy:  0.967\n",
      "Test dataset Accuracy:  0.962\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in trainset:\n",
    "        X, y = data\n",
    "        output = nnet(X.view(-1,784))\n",
    "        #print(output)\n",
    "        for idx, i in enumerate(output):\n",
    "            #print(torch.argmax(i), y[idx])\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "print(\"Train dataset Accuracy: \", round(correct/total, 3))\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testset:\n",
    "        X, y = data\n",
    "        output = nnet(X.view(-1,784))\n",
    "        #print(output)\n",
    "        for idx, i in enumerate(output):\n",
    "            #print(torch.argmax(i), y[idx])\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "print(\"Test dataset Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80338002",
   "metadata": {},
   "source": [
    "##### looking at predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9d3ab99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted output =  tensor(3)\n",
      "target output    =  tensor(3)\n"
     ]
    }
   ],
   "source": [
    "index = 99\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X[index].view(28,28))\n",
    "plt.show()\n",
    "print('predicted output = ',torch.argmax(nnet(X[index].view(-1,784))[0]))\n",
    "print('target output    = ',y[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd58b939",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
