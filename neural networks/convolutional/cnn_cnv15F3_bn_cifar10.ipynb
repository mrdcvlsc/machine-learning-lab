{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_cnv15F3_bn_cifar10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ioi5zxQtnG3Z"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMy4849Tytby",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "350da18c-706f-4a4b-87b9-3ca208218ab4"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19mGycA3nRE9"
      },
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(size=(120,120)),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(),\n",
        "    transforms.CenterCrop(112),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(size=(112,112)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))\n",
        "])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sgz0njZcnykg",
        "outputId": "428b53ba-64d2-4a83-b3be-598967f6bbb4"
      },
      "source": [
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,download=True, transform=train_transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,download=True, transform=test_transform)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83BSS-3Yn4c7"
      },
      "source": [
        "batch_size = 250\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ['plane','car','bird','cat','deer','dog','frog','horse','ship','truck']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQgmVF13n-fG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "262eff6c-38f9-42a3-9e09-983bff90bd2b"
      },
      "source": [
        "import torch.nn as nn\n",
        "from collections import OrderedDict\n",
        "\n",
        "class VGG16bn(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VGG16bn,self).__init__()\n",
        "        self.conv_layer = nn.Sequential(\n",
        "\n",
        "            nn.Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "            nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "            nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "            nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "            nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "            nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "            nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "            nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "            nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "            nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
        "            \n",
        "            nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "            nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "            nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "            nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
        "\n",
        "            nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "            nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "            nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "            nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
        "        )\n",
        "        \n",
        "        self.affine_layer = nn.Sequential(\n",
        "            nn.Linear(in_features=256*3*3, out_features=80, bias=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.5, inplace=False),\n",
        "            nn.Linear(in_features=80, out_features=80, bias=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.5, inplace=False),\n",
        "            nn.Linear(in_features=80, out_features=10, bias=True)\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.conv_layer(x)\n",
        "        x = torch.flatten(x,1)\n",
        "        x = self.affine_layer(x)\n",
        "        return x\n",
        "\n",
        "vgg16_model = VGG16bn()\n",
        "vgg16_model.to(device)\n",
        "# vgg16_model"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG16bn(\n",
              "  (conv_layer): Sequential(\n",
              "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (12): ReLU(inplace=True)\n",
              "    (13): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (14): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (17): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (20): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (21): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (24): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (28): ReLU(inplace=True)\n",
              "    (29): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (30): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (31): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (32): ReLU(inplace=True)\n",
              "    (33): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (34): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (35): ReLU(inplace=True)\n",
              "    (36): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (37): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (38): ReLU(inplace=True)\n",
              "    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (40): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (41): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (42): ReLU(inplace=True)\n",
              "    (43): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (44): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (45): ReLU(inplace=True)\n",
              "    (46): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (47): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (48): ReLU(inplace=True)\n",
              "    (49): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (affine_layer): Sequential(\n",
              "    (0): Linear(in_features=2304, out_features=80, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=80, out_features=80, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=80, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXPsvIqurK1L"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "cost = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(vgg16_model.parameters(), lr=0.001)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC9II8GgycP1",
        "outputId": "560b061a-b777-48a3-f4c0-073958e4494d"
      },
      "source": [
        "import time\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "EPOCH = 10\n",
        "\n",
        "vgg16_model.train()\n",
        "\n",
        "i = 0\n",
        "for epoch in range(EPOCH):\n",
        "    i+=1\n",
        "    print('(',round((i/EPOCH)*100,2),'%) Epoch : ',i,'/',EPOCH, sep='')\n",
        "    for data in trainloader:\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = vgg16_model(inputs)\n",
        "        loss = cost(outputs, labels) # loss function use in tandem with log_softmax\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "end = time.time()\n",
        "            \n",
        "dur_sec = end-start\n",
        "dur_min = dur_sec/60\n",
        "dur_hr  = dur_min/60\n",
        "\n",
        "print('Finished Training, \\nTraining took',dur_sec,'seconds')\n",
        "print(dur_min,'min')\n",
        "print(dur_hr,'hr')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10.0%) Epoch : 1/10\n",
            "(20.0%) Epoch : 2/10\n",
            "(30.0%) Epoch : 3/10\n",
            "(40.0%) Epoch : 4/10\n",
            "(50.0%) Epoch : 5/10\n",
            "(60.0%) Epoch : 6/10\n",
            "(70.0%) Epoch : 7/10\n",
            "(80.0%) Epoch : 8/10\n",
            "(90.0%) Epoch : 9/10\n",
            "(100.0%) Epoch : 10/10\n",
            "Finished Training, \n",
            "Training took 2181.4636318683624 seconds\n",
            "36.35772719780604 min\n",
            "0.6059621199634341 hr\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6LDt1QUyjEf"
      },
      "source": [
        "# index = 0\n",
        "\n",
        "# vgg16_model.eval()\n",
        "\n",
        "# for data in testloader:\n",
        "#     image, label = data[0].to(device), data[1].to(device)\n",
        "#     break\n",
        "\n",
        "# selected_image = torch.unsqueeze(image[index],0).to(device)\n",
        "\n",
        "# imshow(image[index].to('cpu'))\n",
        "# print('Target label : ', classes[label[index]])\n",
        "\n",
        "# prediction = vgg16_model(selected_image)\n",
        "\n",
        "# print('Predicted label : ',classes[prediction.argmax().item()])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2br9ZlM9rJj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b35e90da-50a7-4229-9adf-3f9d35b14db1"
      },
      "source": [
        "start = time.time()\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "vgg16_model.eval()\n",
        "\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in trainloader:\n",
        "        # images, labels = data\n",
        "        images, labels = data[0].to(device), data[1].to(device) # To GPU\n",
        "        # calculate outputs by running images through the network \n",
        "        outputs = vgg16_model(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on training images: %d %%' % (100 * correct / total))\n",
        "        \n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        # images, labels = data\n",
        "        images, labels = data[0].to(device), data[1].to(device) # To GPU\n",
        "        outputs = vgg16_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on testing images: %d %%' % (100 * correct / total))\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print('The whole cell took ',(end-start), 'seconds')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on training images: 91 %\n",
            "Accuracy of the network on testing images: 86 %\n",
            "The whole cell took  92.04662871360779 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6H6h5NTDSuH8"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLjRCuh_Xd5v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22314353-a0a0-4e69-c5df-f755ee04d939"
      },
      "source": [
        "# Access Google Drive Storage\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RX8DcNWyYC_4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c91c5dd-7be1-4663-9354-ca46d5eaa77e"
      },
      "source": [
        "vgg16_model.eval()\n",
        "vgg16_model.to('cpu')\n",
        "PATH = 'drive/MyDrive/Colab Notebooks/cnn_cnv14F3_bn_cifar10_epoch40.pth'\n",
        "torch.save(vgg16_model.state_dict(), PATH)\n",
        "vgg16_model.to(device)\n",
        "\n",
        "# PRETRAINED_PATH = 'drive/MyDrive/Colab Notebooks/cnn_cnv14F3_bn_cifar10_epoch40.pth'\n",
        "\n",
        "# loaded_model = VGG16bn()\n",
        "# loaded_model.load_state_dict(torch.load(PRETRAINED_PATH))\n",
        "# loaded_model.to(device)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG16bn(\n",
              "  (conv_layer): Sequential(\n",
              "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (12): ReLU(inplace=True)\n",
              "    (13): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (14): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (17): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (20): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (21): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (24): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (28): ReLU(inplace=True)\n",
              "    (29): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (30): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (31): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (32): ReLU(inplace=True)\n",
              "    (33): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (34): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (35): ReLU(inplace=True)\n",
              "    (36): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (37): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (38): ReLU(inplace=True)\n",
              "    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (40): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (41): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (42): ReLU(inplace=True)\n",
              "    (43): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (44): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (45): ReLU(inplace=True)\n",
              "    (46): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (47): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (48): ReLU(inplace=True)\n",
              "    (49): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (affine_layer): Sequential(\n",
              "    (0): Linear(in_features=2304, out_features=80, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=80, out_features=80, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=80, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dX9WlUWBaWk",
        "outputId": "a70d1e2e-3243-40f2-89eb-0c120e998e72"
      },
      "source": [
        "start = time.time()\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "loaded_model.eval()\n",
        "\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in trainloader:\n",
        "        # images, labels = data\n",
        "        images, labels = data[0].to(device), data[1].to(device) # To GPU\n",
        "        # calculate outputs by running images through the network \n",
        "        outputs = loaded_model(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on training images: %d %%' % (100 * correct / total))\n",
        "        \n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        # images, labels = data\n",
        "        images, labels = data[0].to(device), data[1].to(device) # To GPU\n",
        "        outputs = loaded_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on testing images: %d %%' % (100 * correct / total))\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print('The whole cell took ',(end-start), 'seconds')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on training images: 88 %\n",
            "Accuracy of the network on testing images: 85 %\n",
            "The whole cell took  92.61602306365967 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRCIE2S8s4dE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}